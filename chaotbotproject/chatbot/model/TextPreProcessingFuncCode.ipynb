{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextPreProcessingFuncCode.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOGs6MDtfQTa",
        "outputId": "d39d9a6c-f2e3-460f-9e81-c17086388abe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install jieba"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jieba in c:\\users\\win10\\anaconda3\\lib\\site-packages (0.42.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RowIfCSKg5-I",
        "outputId": "271ea97a-2027-4a20-c69c-01edb1d24151",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import json\n",
        "import os\n",
        "import sys\n",
        "import urllib.request\n",
        "import copy\n",
        "import csv\n",
        "#from google.colab import drive\n",
        "import jieba as j\n",
        "import pandas as pd\n",
        "\n",
        "#번역함수 -> (번역할 문장, 번역할 언어종류)\n",
        "def translate(sentence, target_lang):\n",
        "    client_id = \"deribthgxo\"\n",
        "    client_secret = \"8NOoY9KhtwKHKZwpOQYr5bovSKA6DSctcC9eClf8\"\n",
        "    encText = urllib.parse.quote(sentence)\n",
        "    data = f\"source=ko&target={target_lang}&text=\" + encText\n",
        "\n",
        "    url = \"https://naveropenapi.apigw.ntruss.com/nmt/v1/translation\"\n",
        "    request = urllib.request.Request(url)\n",
        "    request.add_header(\"X-NCP-APIGW-API-KEY-ID\", client_id)\n",
        "    request.add_header(\"X-NCP-APIGW-API-KEY\", client_secret)\n",
        "    response = urllib.request.urlopen(request, data=data.encode(\"utf-8\"))\n",
        "    rescode = response.getcode()\n",
        "\n",
        "    if (rescode == 200):\n",
        "        response_body = response.read()\n",
        "        result = response_body.decode('utf-8')\n",
        "        json_sentence = json.loads(result)\n",
        "        return json_sentence[\"message\"][\"result\"][\"translatedText\"]\n",
        "\n",
        "    else:\n",
        "        return \"Error Code:\" + rescode\n",
        "\n",
        "\n",
        "#Data 로딩 함수 -> (csv파일 경로, 몇번째 row까지 사용할 것인지 ...)\n",
        "def data_reload(csv_path, start_index, end_index):\n",
        "\n",
        "    data = []\n",
        "    with open(csv_path, 'r', encoding='utf-8') as csvfile:\n",
        "        data_reader = csv.reader(csvfile)\n",
        "        for row in data_reader:\n",
        "            data.append(row)\n",
        "\n",
        "    del data[0] #컬럼 이름이 들어간 row는 del메소드로 삭제해준다.\n",
        "\n",
        "    data = data[start_index : end_index]\n",
        "\n",
        "    return data\n",
        "\n",
        "#불용어 추출 함수 -> (받아온 데이터, 불용어 추출 리스트)\n",
        "def StopWordsFiltering(data, stopwords):\n",
        "    for i, row in enumerate(data):\n",
        "        elem1 = ''.join(row[0])\n",
        "        elem2 = ''.join(row[1])\n",
        "        for s in stopwords:\n",
        "            row1 = elem1.replace(s, \"\")\n",
        "            row2 = elem2.replace(s, \"\")\n",
        "        # row1 = elem1.lstrip().rstrip().replace(\"ㅎ\", \"\").replace(\"~\", \"\").replace(\"ㅠ\", \"\").replace(\"휴\", \"\").replace(\"우\", \"\").replace(\"ㅜ\", \"\")\n",
        "        # row2 = elem2.lstrip().rstrip().replace(\"ㅎ\", \"\").replace(\"~\", \"\").replace(\"ㅠ\", \"\").replace(\"휴\", \"\").replace(\"우\", \"\").replace(\"ㅜ\", \"\")\n",
        "        data[i][0] = row1\n",
        "        data[i][1] = row2 \n",
        "    print(data[:5])\n",
        "    \n",
        "    return data\n",
        "\n",
        "#앞에서 받아온 데이터를 forloop로 일일히 번역해주는 함수! -> (번역할 데이터)\n",
        "def Translate_UsingPAPAGO(trans_data, default_lang): \n",
        "    Q_list = []\n",
        "    A_list = []\n",
        "    label = []\n",
        "\n",
        "    for i, row in enumerate(trans_data):\n",
        "        Q_list.append(translate(row[0], default_lang))\n",
        "        A_list.append(translate(row[1], default_lang))\n",
        "        label.append(row[2])\n",
        "        print(f\"complete-row{i}!\")\n",
        "\n",
        "    for i, j, k in zip(Q_list[:5], A_list[:5], label[:5]):\n",
        "        print(i, j, k)\n",
        "\n",
        "    return Q_list, A_list, label\n",
        "\n",
        "#jieba모듈을 사용해서 문장을 토크나이징 해주는 함수 -> (Q, A, label컬럼에 해당하는 데이터)\n",
        "def jieba_tokenizing(Q_list, A_list, label):\n",
        "    j.enable_paddle()\n",
        "\n",
        "    input_data = {\n",
        "        \"Q\" : [\" \".join(j.cut(q, cut_all=False, use_paddle=True)) for q in Q_list],\n",
        "        \"A\" : [\" \".join(j.cut(a, cut_all=False, use_paddle=True)) for a in A_list],\n",
        "        \"Label\" : [\" \".join(j.cut(l, cut_all=False, use_paddle=True)) for l in label]\n",
        "    }\n",
        "\n",
        "    new_df = pd.DataFrame(input_data)\n",
        "\n",
        "    print(new_df.head(3))\n",
        "\n",
        "    return new_df\n",
        "\n",
        "#Main함수\n",
        "if __name__ == \"__main__\":\n",
        "    csv_path = r\"C:\\Users\\WIN10\\Desktop\\UCCProject\\ChineseChatBotProject\\chaotbotproject\\chatbot\\model\\chinense_sample_data.xlsx\"\n",
        "    \n",
        "    stopwords = [\"ㅎ\", \"~\", \"'\", \"*\", \"^\", \"휴\", \"우\", \"후\", \"ㅠ\", \"ㅜ\", \".\"]\n",
        "    #데이터 임포트\n",
        "    data = data_reload(csv_path, 0, 10) #총 row개수 -> 11824개 (준기[0:3943] 영석[3943:7883] 상민[7883:-1])\n",
        "    #데이터 스탑워드 필터링 !\n",
        "    filtering_data = StopWordsFiltering(data, stopwords)\n",
        "    print(filtering_data)\n",
        "    #번역함수 돌리기!\n",
        "    Q_list, A_list, label = Translate_UsingPAPAGO(filtering_data,  \"zh-CN\")\n",
        "    #jieba 토크나이징 진행하기 !\n",
        "    new_df = jieba_tokenizing(Q_list, A_list, label)\n",
        "    new_df.to_excel(\"chinense_chatbot_data.xlsx\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "'cp949' codec can't decode byte 0xf2 in position 10: illegal multibyte sequence",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-3-a47eec40c624>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[0mstopwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"ㅎ\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"~\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"'\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"*\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"^\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"휴\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"우\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"후\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ㅠ\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ㅜ\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\".\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;31m#데이터 임포트\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_reload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#총 row개수 -> 11824개 (준기[0:3943] 영석[3943:7883] 상민[7883:-1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m     \u001b[1;31m#데이터 스탑워드 필터링 !\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[0mfiltering_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStopWordsFiltering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-3-a47eec40c624>\u001b[0m in \u001b[0;36mdata_reload\u001b[1;34m(csv_path, start_index, end_index)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cp949'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mdata_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_reader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'cp949' codec can't decode byte 0xf2 in position 10: illegal multibyte sequence"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}